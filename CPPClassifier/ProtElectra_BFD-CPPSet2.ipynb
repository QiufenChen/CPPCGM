{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, matthews_corrcoef\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './prot_electra_discriminator_bfd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLocDataset(Dataset):\n",
    "    def __init__(self, split=\"train\", tokenizer_name='Rostlab/prot_bert', max_length=1024):\n",
    "        self.datasetFolderPath = 'dataset/'\n",
    "        self.trainFilePath = os.path.join(self.datasetFolderPath, 'train.csv')\n",
    "        self.testFilePath = os.path.join(self.datasetFolderPath, 'test.csv')\n",
    "        self.validFilePath = os.path.join(self.datasetFolderPath, 'valid.csv')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name, do_lower_case=False)\n",
    "        if split==\"train\":\n",
    "            self.seqs, self.labels = self.load_dataset(self.trainFilePath)\n",
    "        if split==\"test\":\n",
    "            self.seqs, self.labels = self.load_dataset(self.testFilePath)\n",
    "        if split==\"valid\":\n",
    "            self.seqs, self.labels = self.load_dataset(self.validFilePath)\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def load_dataset(self,path):\n",
    "        df = pd.read_csv(path,names=['input','labels'],skiprows=1)\n",
    "        seq = list(df['input'])\n",
    "        seq = [' '.join(i) for i in seq]\n",
    "        label = list(df['labels'])\n",
    "        assert len(seq) == len(label)\n",
    "        return seq, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        seq = \" \".join(\"\".join(self.seqs[idx].split()))\n",
    "        seq = re.sub(r\"[UZOB]\", \"X\", seq)\n",
    "        seq_ids = self.tokenizer(seq, truncation=True, padding='max_length', max_length=self.max_length)\n",
    "        sample = {key: torch.tensor(val) for key, val in seq_ids.items()}\n",
    "        sample['labels'] = torch.tensor(self.labels[idx])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DeepLocDataset(split=\"train\", tokenizer_name=model_name, max_length=80)\n",
    "test_dataset = DeepLocDataset(split=\"test\", tokenizer_name=model_name, max_length=80)\n",
    "valid_dataset = DeepLocDataset(split=\"valid\", tokenizer_name=model_name, max_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'mcc' : matthews_corrcoef(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "      return AutoModelForSequenceClassification.from_pretrained(model_name)#.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./prot_electra_discriminator_bfd were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at ./prot_electra_discriminator_bfd and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the model checkpoint at ./prot_electra_discriminator_bfd were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at ./prot_electra_discriminator_bfd and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [52/52 15:04, Epoch 25/26]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Mcc</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.667402</td>\n",
       "      <td>0.786957</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.575240</td>\n",
       "      <td>2.672100</td>\n",
       "      <td>172.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.944700</td>\n",
       "      <td>0.596062</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.855346</td>\n",
       "      <td>0.898678</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.703860</td>\n",
       "      <td>2.668300</td>\n",
       "      <td>172.392000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.812600</td>\n",
       "      <td>0.479581</td>\n",
       "      <td>0.863043</td>\n",
       "      <td>0.875740</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>0.723604</td>\n",
       "      <td>2.676400</td>\n",
       "      <td>171.871000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.636200</td>\n",
       "      <td>0.358180</td>\n",
       "      <td>0.882609</td>\n",
       "      <td>0.894942</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.763613</td>\n",
       "      <td>2.644000</td>\n",
       "      <td>173.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>0.276343</td>\n",
       "      <td>0.889130</td>\n",
       "      <td>0.905028</td>\n",
       "      <td>0.846690</td>\n",
       "      <td>0.972000</td>\n",
       "      <td>0.784047</td>\n",
       "      <td>2.671300</td>\n",
       "      <td>172.198000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.301503</td>\n",
       "      <td>0.886957</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.834459</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>0.784815</td>\n",
       "      <td>2.675400</td>\n",
       "      <td>171.936000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.382600</td>\n",
       "      <td>0.205989</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>0.926357</td>\n",
       "      <td>0.898496</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.834581</td>\n",
       "      <td>2.673300</td>\n",
       "      <td>172.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>0.211644</td>\n",
       "      <td>0.921739</td>\n",
       "      <td>0.926230</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>0.844160</td>\n",
       "      <td>2.723000</td>\n",
       "      <td>168.928000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.255300</td>\n",
       "      <td>0.203769</td>\n",
       "      <td>0.915217</td>\n",
       "      <td>0.923379</td>\n",
       "      <td>0.907336</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.829204</td>\n",
       "      <td>2.686100</td>\n",
       "      <td>171.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.212536</td>\n",
       "      <td>0.921739</td>\n",
       "      <td>0.928854</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.842217</td>\n",
       "      <td>2.665500</td>\n",
       "      <td>172.573000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.197013</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.950884</td>\n",
       "      <td>0.934363</td>\n",
       "      <td>0.968000</td>\n",
       "      <td>0.890797</td>\n",
       "      <td>2.668100</td>\n",
       "      <td>172.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.140700</td>\n",
       "      <td>0.185407</td>\n",
       "      <td>0.936957</td>\n",
       "      <td>0.941414</td>\n",
       "      <td>0.951020</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.873403</td>\n",
       "      <td>2.675000</td>\n",
       "      <td>171.963000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.096400</td>\n",
       "      <td>0.212641</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.945098</td>\n",
       "      <td>0.926923</td>\n",
       "      <td>0.964000</td>\n",
       "      <td>0.877713</td>\n",
       "      <td>2.560700</td>\n",
       "      <td>179.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.079400</td>\n",
       "      <td>0.223646</td>\n",
       "      <td>0.936957</td>\n",
       "      <td>0.943026</td>\n",
       "      <td>0.926641</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.873199</td>\n",
       "      <td>2.682300</td>\n",
       "      <td>171.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.253433</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.943320</td>\n",
       "      <td>0.954918</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.877915</td>\n",
       "      <td>2.664000</td>\n",
       "      <td>172.674000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.065800</td>\n",
       "      <td>0.241555</td>\n",
       "      <td>0.941304</td>\n",
       "      <td>0.945674</td>\n",
       "      <td>0.951417</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.881925</td>\n",
       "      <td>2.665500</td>\n",
       "      <td>172.578000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.246964</td>\n",
       "      <td>0.936957</td>\n",
       "      <td>0.942116</td>\n",
       "      <td>0.940239</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.872912</td>\n",
       "      <td>2.666200</td>\n",
       "      <td>172.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.034000</td>\n",
       "      <td>0.262802</td>\n",
       "      <td>0.943478</td>\n",
       "      <td>0.947791</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.886216</td>\n",
       "      <td>2.755400</td>\n",
       "      <td>166.948000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>0.266366</td>\n",
       "      <td>0.943478</td>\n",
       "      <td>0.947581</td>\n",
       "      <td>0.955285</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.886404</td>\n",
       "      <td>2.682200</td>\n",
       "      <td>171.504000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.019200</td>\n",
       "      <td>0.269962</td>\n",
       "      <td>0.943478</td>\n",
       "      <td>0.947581</td>\n",
       "      <td>0.955285</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.886404</td>\n",
       "      <td>2.727400</td>\n",
       "      <td>168.662000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.284626</td>\n",
       "      <td>0.943478</td>\n",
       "      <td>0.947791</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.944000</td>\n",
       "      <td>0.886216</td>\n",
       "      <td>2.666700</td>\n",
       "      <td>172.499000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.292465</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.939516</td>\n",
       "      <td>0.947154</td>\n",
       "      <td>0.932000</td>\n",
       "      <td>0.868904</td>\n",
       "      <td>2.676800</td>\n",
       "      <td>171.847000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.290874</td>\n",
       "      <td>0.936957</td>\n",
       "      <td>0.941884</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.873009</td>\n",
       "      <td>2.684000</td>\n",
       "      <td>171.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.284387</td>\n",
       "      <td>0.936957</td>\n",
       "      <td>0.941884</td>\n",
       "      <td>0.943775</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.873009</td>\n",
       "      <td>2.777800</td>\n",
       "      <td>165.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.277250</td>\n",
       "      <td>0.941304</td>\n",
       "      <td>0.946108</td>\n",
       "      <td>0.944223</td>\n",
       "      <td>0.948000</td>\n",
       "      <td>0.881678</td>\n",
       "      <td>2.677100</td>\n",
       "      <td>171.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.276922</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.952191</td>\n",
       "      <td>0.948413</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.894811</td>\n",
       "      <td>2.671000</td>\n",
       "      <td>172.221000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=52, training_loss=0.22577038751198694, metrics={'train_runtime': 920.2907, 'train_samples_per_second': 0.057, 'total_flos': 15473995323676800, 'epoch': 25.7})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=1e-4,\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=26,\n",
    "    per_device_train_batch_size=10,\n",
    "    per_device_eval_batch_size=10,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=2,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    gradient_accumulation_steps=64,\n",
    "    fp16=True,\n",
    "    fp16_opt_level=\"02\",\n",
    "    run_name=\"ProBert-BFD-MS\",\n",
    "    seed=3401\n",
    ")\n",
    "\n",
    "# 26\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = './model/MLCPPele-947.pt'\n",
    "def model_init():\n",
    "      return AutoModelForSequenceClassification.from_pretrained(model_name).cuda()\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,\n",
    "    #args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics = compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 4.826432228088379,\n",
       " 'eval_accuracy': 0.16666666666666666,\n",
       " 'eval_f1': 0.0,\n",
       " 'eval_precision': 0.0,\n",
       " 'eval_recall': 0.0,\n",
       " 'eval_mcc': 0.0,\n",
       " 'eval_runtime': 1.6469,\n",
       " 'eval_samples_per_second': 54.65}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./model/MLCPPele-947.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = trainer.predict(valid_dataset).predictions\n",
    "golden = trainer.predict(valid_dataset).label_ids\n",
    "result = torch.argmax(torch.tensor(result), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaild_dataset = DeepLocDataset(split=\"valid\", tokenizer_name=model_name, max_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-41ca2deceb15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresultv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaild_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgoldenv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaild_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mresultv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresultv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresultv\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m         output = self.prediction_loop(\n\u001b[1;32m-> 1503\u001b[1;33m             \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1504\u001b[0m         )\n\u001b[0;32m   1505\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeed_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \"\"\"\n\u001b[0;32m   1659\u001b[0m         \u001b[0mhas_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1660\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_keys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1662\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m                 \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "resultv = trainer.predict(vaild_dataset).predictions\n",
    "goldenv = trainer.predict(vaild_dataset).label_ids\n",
    "resultv = torch.argmax(torch.tensor(resultv), -1)\n",
    "resultv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goldenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-4f6db8a0133f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvaild_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1502\u001b[0m         output = self.prediction_loop(\n\u001b[1;32m-> 1503\u001b[1;33m             \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1504\u001b[0m         )\n\u001b[0;32m   1505\u001b[0m         \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeed_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1565\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1566\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1567\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1568\u001b[0m                 \u001b[0mlosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[1;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[0;32m   1658\u001b[0m         \"\"\"\n\u001b[0;32m   1659\u001b[0m         \u001b[0mhas_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1660\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1661\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mignore_keys\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1662\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\python\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m                 \u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpast_index\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_past\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "trainer.predict(vaild_dataset).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
